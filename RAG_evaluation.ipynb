{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f3705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from ragas.evaluation import evaluate\n",
    "from ragas.metrics import answer_relevancy, faithfulness, answer_correctness, context_recall, context_precision, answer_similarity\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain import hub\n",
    "import openai\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "asyncio.set_event_loop_policy(asyncio.DefaultEventLoopPolicy())\n",
    "nest_asyncio.apply()\n",
    "import gradio as gr\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Ensure you have set this in your .env file\n",
    "embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "vectorstore = FAISS.load_local(\"nba_vector_db_semantic\", embeddings=embedding, allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bcbd471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import openai\n",
    "\n",
    "# 1) Import RateLimitError (with a fallback to a generic Exception if the import fails)\n",
    "try:\n",
    "    from openai.error import RateLimitError\n",
    "except ImportError:\n",
    "    RateLimitError = Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ee78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheap_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a02dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = vectorstore.docstore._dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af81b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "sparse_retriever = BM25Retriever.from_documents(list(documents), k=10)\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[dense_retriever, sparse_retriever], weights=[0.5, 0.5], c=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cdecca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\16343\\anaconda3\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"jclemens24/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ba2968",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Given the following question and retrieved context, determine if the context is relevant to the question.\n",
    "    Provide a score from 1 to 5, where 1 is not at all relevant and 5 is highly relevant.\n",
    "    Return ONLY the numeric score, without any additional text or explanation.\n",
    "\n",
    "    Question: {question}\n",
    "    Retrieved Context: {retrieved_context}\n",
    "\n",
    "    Relevance Score:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7baffb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    " return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c47f2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_score(llm_output):\n",
    "    try:\n",
    "        score = float(llm_output.strip())\n",
    "        return score\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "# Chain it all together with LangChain\n",
    "def conditional_answer(x):\n",
    "    relevance_score = extract_score(x['relevance_score'])\n",
    "    if relevance_score < 2:\n",
    "        return \"I don't know.\"\n",
    "    else:\n",
    "        return x['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d28c5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "str_output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6224bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the chain\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | RunnableParallel(\n",
    "        {\"relevance_score\": (\n",
    "            RunnablePassthrough()\n",
    "            | (lambda x: relevance_prompt_template.format(question=x['question'], retrieved_context=x['context']))\n",
    "            | llm\n",
    "            | str_output_parser\n",
    "        ), \"answer\": (\n",
    "            RunnablePassthrough()\n",
    "            | prompt\n",
    "            | llm\n",
    "            | str_output_parser\n",
    "        )}\n",
    "    )\n",
    "    | RunnablePassthrough().assign(final_answer=conditional_answer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657b491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_with_source_dense = RunnableParallel(\n",
    "    {\"context\": dense_retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad0a7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_with_source_ensemble = RunnableParallel(\n",
    "    {\"context\": ensemble_retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04a00d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many 3-pointers did Kemba Walker make in t...</td>\n",
       "      <td>Walker made 250 3-pointers in the 2018-2019 NB...</td>\n",
       "      <td>On November 17, he scored a career-high and fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who did Ray Allen co-star alongside in 2015?</td>\n",
       "      <td>Kyrie Irving, Baron Davis, and J.</td>\n",
       "      <td>In 2015, Allen co-starred alongside Kyrie Irvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What college did Miye Oni play basketball for?</td>\n",
       "      <td>Yale Bulldogs</td>\n",
       "      <td>Olumiye Dimolu \"Miye\" Oni (born August 4, 1997...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what year did AJ Green record his fourth co...</td>\n",
       "      <td>2015</td>\n",
       "      <td>In Week 5, against the New England Patriots, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was Ronald Dupree's shooting percentage f...</td>\n",
       "      <td>0.286</td>\n",
       "      <td>He shot 0.286 from the field, 0.0 from 3-point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In which year did Kirk Haston play basketball?</td>\n",
       "      <td>Kirk Haston played basketball in the year ment...</td>\n",
       "      <td>Basketball\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In what year was Adonal Foyle inducted into th...</td>\n",
       "      <td>2009</td>\n",
       "      <td>He also became a member of the National Basket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In which year did Cozell McQueen lead the Ital...</td>\n",
       "      <td>1988–89</td>\n",
       "      <td>Though he briefly played in the NBA for the De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In which year did Brandon Ingram represent the...</td>\n",
       "      <td>...</td>\n",
       "      <td>Olympic basketball team.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What were Greg Brown III's shooting percentage...</td>\n",
       "      <td>Greg Brown III shot 0.42 from the field, 0.33 ...</td>\n",
       "      <td>He shot 0.42 from the field, 0.33 from 3-point...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How many 3-pointers did Kemba Walker make in t...   \n",
       "1       Who did Ray Allen co-star alongside in 2015?   \n",
       "2     What college did Miye Oni play basketball for?   \n",
       "3  In what year did AJ Green record his fourth co...   \n",
       "4  What was Ronald Dupree's shooting percentage f...   \n",
       "5     In which year did Kirk Haston play basketball?   \n",
       "6  In what year was Adonal Foyle inducted into th...   \n",
       "7  In which year did Cozell McQueen lead the Ital...   \n",
       "8  In which year did Brandon Ingram represent the...   \n",
       "9  What were Greg Brown III's shooting percentage...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  Walker made 250 3-pointers in the 2018-2019 NB...   \n",
       "1                  Kyrie Irving, Baron Davis, and J.   \n",
       "2                                      Yale Bulldogs   \n",
       "3                                               2015   \n",
       "4                                              0.286   \n",
       "5  Kirk Haston played basketball in the year ment...   \n",
       "6                                               2009   \n",
       "7                                            1988–89   \n",
       "8                                                ...   \n",
       "9  Greg Brown III shot 0.42 from the field, 0.33 ...   \n",
       "\n",
       "                                             context  \n",
       "0  On November 17, he scored a career-high and fr...  \n",
       "1  In 2015, Allen co-starred alongside Kyrie Irvi...  \n",
       "2  Olumiye Dimolu \"Miye\" Oni (born August 4, 1997...  \n",
       "3  In Week 5, against the New England Patriots, h...  \n",
       "4  He shot 0.286 from the field, 0.0 from 3-point...  \n",
       "5                                       Basketball\".  \n",
       "6  He also became a member of the National Basket...  \n",
       "7  Though he briefly played in the NBA for the De...  \n",
       "8                           Olympic basketball team.  \n",
       "9  He shot 0.42 from the field, 0.33 from 3-point...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read the dataset\n",
    "df = pd.read_csv(\"nba_generated_qa.csv\")\n",
    "#rename the answer column to groud_truth\n",
    "df.rename(columns={\"answer\": \"ground_truth\"}, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3584d2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'ground_truth', 'context'],\n",
       "    num_rows: 76\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_data = df.astype(str).to_dict(orient=\"list\")\n",
    "saved_testing_dataset = Dataset.from_dict(saved_data)\n",
    "saved_testing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abcd1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question, ground_truth, rag_chain):\n",
    "    result = rag_chain.invoke(question)\n",
    "    return {\n",
    "    \"question\": question,\n",
    "    \"answer\": result[\"answer\"][\"final_answer\"],\n",
    "    \"contexts\": [doc.page_content for doc in result[\"context\"]],\n",
    "    \"ground_truth\": ground_truth\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8dcbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_generate_answer(question, ground_truth, chain, max_retries=5):\n",
    "    delay = 1.0\n",
    "    for _ in range(max_retries):\n",
    "        try:\n",
    "            return generate_answer(question, ground_truth, chain)\n",
    "        except RateLimitError:\n",
    "            print(f\"Rate limit hit, retrying in {delay}s…\")\n",
    "            time.sleep(delay)\n",
    "            delay *= 2\n",
    "    # if we still fail, return a placeholder\n",
    "    return {\n",
    "        \"predicted_answer\": None,\n",
    "        \"similarity_score\": None,\n",
    "        \"error\": \"rate_limit_exceeded\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8301bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x000001DA4C444C20> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc77dd445ef4acc9501a9bbf167f327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n"
     ]
    }
   ],
   "source": [
    "testing_dataset_similarity = saved_testing_dataset.map(\n",
    "    lambda ex: safe_generate_answer(\n",
    "        ex[\"question\"],\n",
    "        ex[\"ground_truth\"],\n",
    "        rag_chain_with_source_dense\n",
    "    ),\n",
    "    batched=False,\n",
    "    remove_columns=saved_testing_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b982a93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7841f24dda6c4d7bb7dbe587842f6175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[72]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 197695, Requested 3571. Please try again in 379ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[69]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 197971, Requested 8399. Please try again in 1.911s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[90]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 197563, Requested 10941. Please try again in 2.551s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[84]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 196327, Requested 6925. Please try again in 975ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[60]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 200000, Requested 8582. Please try again in 2.574s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[63]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 198020, Requested 8595. Please try again in 1.984s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[102]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 197560, Requested 5724. Please try again in 985ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[66]: TimeoutError()\n",
      "Exception raised in Job[123]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 192751, Requested 8544. Please try again in 388ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[165]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 198376, Requested 9138. Please try again in 2.254s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[177]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 198777, Requested 7188. Please try again in 1.789s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[162]: TimeoutError()\n",
      "Exception raised in Job[174]: TimeoutError()\n",
      "Exception raised in Job[192]: TimeoutError()\n",
      "Exception raised in Job[222]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 200000, Requested 7605. Please try again in 2.281s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[204]: TimeoutError()\n",
      "Exception raised in Job[213]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 200000, Requested 8975. Please try again in 2.692s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[225]: TimeoutError()\n",
      "Exception raised in Job[255]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 197691, Requested 6901. Please try again in 1.377s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[270]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 199476, Requested 9602. Please try again in 2.723s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[273]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 198455, Requested 9646. Please try again in 2.43s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[294]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 200000, Requested 7418. Please try again in 2.225s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[321]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 198913, Requested 8988. Please try again in 2.37s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[354]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 197637, Requested 6967. Please try again in 1.381s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[318]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 196432, Requested 9040. Please try again in 1.641s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
     ]
    }
   ],
   "source": [
    "score_similarity = evaluate(\n",
    "    testing_dataset_similarity,\n",
    "    metrics=[\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    " ],\n",
    " llm=cheap_llm\n",
    ")\n",
    "similarity_df = score_similarity.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "381c545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_columns = ['faithfulness', 'answer_relevancy', 'context_precision', 'context_recall', 'answer_correctness', 'semantic_similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ed16d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many 3-pointers did Kemba Walker make in t...</td>\n",
       "      <td>[Augustin, he became their starting point guar...</td>\n",
       "      <td>Kemba Walker made 250 three-pointers in the 20...</td>\n",
       "      <td>Walker made 250 3-pointers in the 2018-2019 NB...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996949</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.729575</td>\n",
       "      <td>0.918301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who did Ray Allen co-star alongside in 2015?</td>\n",
       "      <td>[In 2015, Allen co-starred alongside Kyrie Irv...</td>\n",
       "      <td>In 2015, Ray Allen co-starred alongside Kyrie ...</td>\n",
       "      <td>Kyrie Irving, Baron Davis, and J.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.977542</td>\n",
       "      <td>0.910168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What college did Miye Oni play basketball for?</td>\n",
       "      <td>[Olumiye Dimolu \"Miye\" Oni (born August 4, 199...</td>\n",
       "      <td>Miye Oni played college basketball for the Yal...</td>\n",
       "      <td>Yale Bulldogs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982126</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.714126</td>\n",
       "      <td>0.856506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what year did AJ Green record his fourth co...</td>\n",
       "      <td>[He followed that up with eight receptions for...</td>\n",
       "      <td>AJ Green recorded his fourth consecutive 1,000...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911119</td>\n",
       "      <td>0.592619</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.839809</td>\n",
       "      <td>0.787749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was Ronald Dupree's shooting percentage f...</td>\n",
       "      <td>[Ronald Edmund Dupree Jr. (born January 26, 19...</td>\n",
       "      <td>Ronald Dupree's shooting percentage from the f...</td>\n",
       "      <td>0.286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.193134</td>\n",
       "      <td>0.772537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>What was Anthony Johnson's shooting percentage...</td>\n",
       "      <td>[He shot 0.371 from the field, 0.328 from 3-po...</td>\n",
       "      <td>Anthony Johnson's shooting percentage from the...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.192842</td>\n",
       "      <td>0.771424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>In which year did Vlatko Čančar win his first ...</td>\n",
       "      <td>[Vlatko Čančar ( CHAHN-char; born 10 April 199...</td>\n",
       "      <td>Vlatko Čančar won his first NBA championship w...</td>\n",
       "      <td>In June 2023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958585</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.704641</td>\n",
       "      <td>0.818565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>What event led to Michael Jordan becoming a gr...</td>\n",
       "      <td>[He has two older brothers, James Jr. and Larr...</td>\n",
       "      <td>Michael Jordan became a grandfather in 2019 wh...</td>\n",
       "      <td>His daughter Jasmine giving birth to a son, wh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953684</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>0.890777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>What significant achievement did Rumeal Robins...</td>\n",
       "      <td>[Shortly after he turned 10 years old, his gra...</td>\n",
       "      <td>During his junior year in 1989, Rumeal Robinso...</td>\n",
       "      <td>Rumeal Robinson sank two crucial free throws w...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989923</td>\n",
       "      <td>0.807341</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.673087</td>\n",
       "      <td>0.978061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>In which season did Darius Morris play for Mem...</td>\n",
       "      <td>[He shot .308 from the field, .000 from 3-poin...</td>\n",
       "      <td>Darius Morris played for Memphis in the 2013–1...</td>\n",
       "      <td>Darius Morris played for Memphis in the 2013-1...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.932784</td>\n",
       "      <td>0.825926</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.434416</td>\n",
       "      <td>0.987542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   How many 3-pointers did Kemba Walker make in t...   \n",
       "1        Who did Ray Allen co-star alongside in 2015?   \n",
       "2      What college did Miye Oni play basketball for?   \n",
       "3   In what year did AJ Green record his fourth co...   \n",
       "4   What was Ronald Dupree's shooting percentage f...   \n",
       "..                                                ...   \n",
       "71  What was Anthony Johnson's shooting percentage...   \n",
       "72  In which year did Vlatko Čančar win his first ...   \n",
       "73  What event led to Michael Jordan becoming a gr...   \n",
       "74  What significant achievement did Rumeal Robins...   \n",
       "75  In which season did Darius Morris play for Mem...   \n",
       "\n",
       "                                   retrieved_contexts  \\\n",
       "0   [Augustin, he became their starting point guar...   \n",
       "1   [In 2015, Allen co-starred alongside Kyrie Irv...   \n",
       "2   [Olumiye Dimolu \"Miye\" Oni (born August 4, 199...   \n",
       "3   [He followed that up with eight receptions for...   \n",
       "4   [Ronald Edmund Dupree Jr. (born January 26, 19...   \n",
       "..                                                ...   \n",
       "71  [He shot 0.371 from the field, 0.328 from 3-po...   \n",
       "72  [Vlatko Čančar ( CHAHN-char; born 10 April 199...   \n",
       "73  [He has two older brothers, James Jr. and Larr...   \n",
       "74  [Shortly after he turned 10 years old, his gra...   \n",
       "75  [He shot .308 from the field, .000 from 3-poin...   \n",
       "\n",
       "                                             response  \\\n",
       "0   Kemba Walker made 250 three-pointers in the 20...   \n",
       "1   In 2015, Ray Allen co-starred alongside Kyrie ...   \n",
       "2   Miye Oni played college basketball for the Yal...   \n",
       "3   AJ Green recorded his fourth consecutive 1,000...   \n",
       "4   Ronald Dupree's shooting percentage from the f...   \n",
       "..                                                ...   \n",
       "71  Anthony Johnson's shooting percentage from the...   \n",
       "72  Vlatko Čančar won his first NBA championship w...   \n",
       "73  Michael Jordan became a grandfather in 2019 wh...   \n",
       "74  During his junior year in 1989, Rumeal Robinso...   \n",
       "75  Darius Morris played for Memphis in the 2013–1...   \n",
       "\n",
       "                                            reference  faithfulness  \\\n",
       "0   Walker made 250 3-pointers in the 2018-2019 NB...           0.0   \n",
       "1                   Kyrie Irving, Baron Davis, and J.           0.0   \n",
       "2                                       Yale Bulldogs           1.0   \n",
       "3                                                2015           0.0   \n",
       "4                                               0.286           1.0   \n",
       "..                                                ...           ...   \n",
       "71                                                0.5           0.5   \n",
       "72                                       In June 2023           1.0   \n",
       "73  His daughter Jasmine giving birth to a son, wh...           0.0   \n",
       "74  Rumeal Robinson sank two crucial free throws w...           1.0   \n",
       "75  Darius Morris played for Memphis in the 2013-1...           0.5   \n",
       "\n",
       "    answer_relevancy  context_precision  context_recall  answer_correctness  \\\n",
       "0           0.996949           0.944444            1.00            0.729575   \n",
       "1           1.000000           0.000000            1.00            0.977542   \n",
       "2           0.982126           0.966667            0.20            0.714126   \n",
       "3           0.911119           0.592619            0.75            0.839809   \n",
       "4           0.970677           1.000000            0.00            0.193134   \n",
       "..               ...                ...             ...                 ...   \n",
       "71          1.000000           0.808333            0.60            0.192842   \n",
       "72          0.958585           0.500000            1.00            0.704641   \n",
       "73          0.953684           0.450000            0.00            0.722694   \n",
       "74          0.989923           0.807341            1.00            0.673087   \n",
       "75          0.932784           0.825926            1.00            0.434416   \n",
       "\n",
       "    semantic_similarity  \n",
       "0              0.918301  \n",
       "1              0.910168  \n",
       "2              0.856506  \n",
       "3              0.787749  \n",
       "4              0.772537  \n",
       "..                  ...  \n",
       "71             0.771424  \n",
       "72             0.818565  \n",
       "73             0.890777  \n",
       "74             0.978061  \n",
       "75             0.987542  \n",
       "\n",
       "[76 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d8e2738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faithfulness           0.569672\n",
       "answer_relevancy       0.813273\n",
       "context_precision      0.702329\n",
       "context_recall         0.750758\n",
       "answer_correctness     0.640485\n",
       "semantic_similarity    0.858064\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_means = similarity_df[key_columns].mean()\n",
    "similarity_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdf864f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df.to_csv(\"evaluation_dense.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e51ace3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c2400e18684eb0a3acbbb6d2152ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 2.0s…\n",
      "Rate limit hit, retrying in 4.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 2.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 2.0s…\n",
      "Rate limit hit, retrying in 4.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 2.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n",
      "Rate limit hit, retrying in 1.0s…\n"
     ]
    }
   ],
   "source": [
    "testing_dataset_hybrid = saved_testing_dataset.map(\n",
    "    lambda ex: safe_generate_answer(\n",
    "        ex[\"question\"],\n",
    "        ex[\"ground_truth\"],\n",
    "        rag_chain_with_source_ensemble\n",
    "    ),\n",
    "    batched=False,\n",
    "    remove_columns=saved_testing_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c37cd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4026c6c532164d1f9e6b3b6e20065024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[21]: BadRequestError(Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 18514 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})\n",
      "Exception raised in Job[18]: BadRequestError(Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 18463 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})\n",
      "Exception raised in Job[51]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 196680, Requested 11157. Please try again in 2.351s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[54]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 197491, Requested 12613. Please try again in 3.031s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[48]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 199204, Requested 11106. Please try again in 3.093s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n",
      "Exception raised in Job[66]: TimeoutError()\n",
      "Exception raised in Job[87]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 191915, Requested 12950. Please try again in 1.459s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[90]: TimeoutError()\n",
      "Exception raised in Job[174]: BadRequestError(Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 16569 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})\n",
      "Exception raised in Job[93]: TimeoutError()\n",
      "Exception raised in Job[123]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 200000, Requested 12272. Please try again in 3.681s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[117]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 198207, Requested 4993. Please try again in 960ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[105]: TimeoutError()\n",
      "Exception raised in Job[135]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 195080, Requested 10163. Please try again in 1.572s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[144]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 200000, Requested 9279. Please try again in 2.783s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[108]: TimeoutError()\n",
      "Exception raised in Job[111]: TimeoutError()\n",
      "Exception raised in Job[120]: TimeoutError()\n",
      "Exception raised in Job[150]: TimeoutError()\n",
      "Exception raised in Job[162]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 198839, Requested 16472. Please try again in 4.593s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[165]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 195241, Requested 16505. Please try again in 3.523s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[177]: TimeoutError()\n",
      "Exception raised in Job[210]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 188789, Requested 15076. Please try again in 1.159s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[186]: TimeoutError()\n",
      "Exception raised in Job[189]: TimeoutError()\n",
      "Exception raised in Job[195]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 198875, Requested 8817. Please try again in 2.307s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[204]: TimeoutError()\n",
      "Exception raised in Job[213]: TimeoutError()\n",
      "Exception raised in Job[228]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 195158, Requested 19560. Please try again in 4.415s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[231]: TimeoutError()\n",
      "Exception raised in Job[240]: TimeoutError()\n",
      "Exception raised in Job[312]: LLMDidNotFinishException(The LLM generation was not completed. Please increase the max_tokens and try again.)\n",
      "Exception raised in Job[279]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 192688, Requested 9634. Please try again in 696ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[252]: TimeoutError()\n",
      "Exception raised in Job[255]: TimeoutError()\n",
      "Exception raised in Job[270]: TimeoutError()\n",
      "Exception raised in Job[273]: TimeoutError()\n",
      "Exception raised in Job[288]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 196061, Requested 11128. Please try again in 2.156s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[291]: TimeoutError()\n",
      "Exception raised in Job[294]: TimeoutError()\n",
      "Exception raised in Job[309]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 190693, Requested 10051. Please try again in 223ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[315]: TimeoutError()\n",
      "Exception raised in Job[318]: TimeoutError()\n",
      "Exception raised in Job[321]: TimeoutError()\n",
      "Exception raised in Job[342]: TimeoutError()\n",
      "Exception raised in Job[345]: TimeoutError()\n",
      "Exception raised in Job[354]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-rdgbPDQbOKFwp8vaWQzMQLnQ on tokens per min (TPM): Limit 200000, Used 194753, Requested 18233. Please try again in 3.895s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[351]: TimeoutError()\n",
      "Exception raised in Job[357]: TimeoutError()\n",
      "Exception raised in Job[366]: TimeoutError()\n",
      "Exception raised in Job[369]: TimeoutError()\n",
      "Exception raised in Job[441]: BadRequestError(Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 16884 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})\n",
      "Exception raised in Job[438]: BadRequestError(Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 16855 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}})\n"
     ]
    }
   ],
   "source": [
    "score_similarity = evaluate(\n",
    "    testing_dataset_hybrid,\n",
    "    metrics=[\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    " ],\n",
    " llm=cheap_llm\n",
    ")\n",
    "hybrid_df = score_similarity.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73334611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faithfulness           0.565972\n",
       "answer_relevancy       0.809999\n",
       "context_precision      0.687688\n",
       "context_recall         0.819565\n",
       "answer_correctness     0.638502\n",
       "semantic_similarity    0.864974\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_means = hybrid_df[key_columns].mean()\n",
    "hybrid_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b36c56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faithfulness           0.569672\n",
       "answer_relevancy       0.813273\n",
       "context_precision      0.702329\n",
       "context_recall         0.750758\n",
       "answer_correctness     0.640485\n",
       "semantic_similarity    0.858064\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f8a76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_df.to_csv(\"evaluation_hybrid.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
