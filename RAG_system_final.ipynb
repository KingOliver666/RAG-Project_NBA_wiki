{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b36adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16343\\AppData\\Local\\Temp\\ipykernel_19288\\268236888.py:25: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# ✅ Step 1: Load environment variables\n",
    "load_dotenv()\n",
    "# Make sure to set your OpenAI API key in the .env file or directly here\n",
    "\n",
    "# ✅ Step 2: Import libraries\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain import hub\n",
    "import openai\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "asyncio.set_event_loop_policy(asyncio.DefaultEventLoopPolicy())\n",
    "nest_asyncio.apply()\n",
    "import gradio as gr\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Ensure you have set this in your .env file\n",
    "embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "vectorstore = FAISS.load_local(\"nba_vector_db\", embeddings=embedding, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834a306e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\16343\\anaconda3\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Define the Retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\\\n",
    "## Define the prompt\n",
    "prompt = hub.pull(\"jclemens24/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7237da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Given the following question and retrieved context, determine if the context is relevant to the question.\n",
    "    Provide a score from 1 to 5, where 1 is not at all relevant and 5 is highly relevant.\n",
    "    Return ONLY the numeric score, without any additional text or explanation.\n",
    "\n",
    "    Question: {question}\n",
    "    Retrieved Context: {retrieved_context}\n",
    "\n",
    "    Relevance Score:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5d91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    " return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8126f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_score(llm_output):\n",
    "    try:\n",
    "        score = float(llm_output.strip())\n",
    "        return score\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "# Chain it all together with LangChain\n",
    "def conditional_answer(x):\n",
    "    relevance_score = extract_score(x['relevance_score'])\n",
    "    if relevance_score < 4:\n",
    "        return \"I don't know.\"\n",
    "    else:\n",
    "        return x['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72cb5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "str_output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2171b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the chain\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | RunnableParallel(\n",
    "        {\"relevance_score\": (\n",
    "            RunnablePassthrough()\n",
    "            | (lambda x: relevance_prompt_template.format(question=x['question'], retrieved_context=x['context']))\n",
    "            | llm\n",
    "            | str_output_parser\n",
    "        ), \"answer\": (\n",
    "            RunnablePassthrough()\n",
    "            | prompt\n",
    "            | llm\n",
    "            | str_output_parser\n",
    "        )}\n",
    "    )\n",
    "    | RunnablePassthrough().assign(final_answer=conditional_answer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "935b8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f5eded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Score: 5\n",
      "Final Answer:\n",
      "The GOAT (Greatest of All Time) of the NBA is often considered to be Michael Jordan. Many of his contemporaries and analysts regard him as the greatest basketball player of all time, and polls typically show Jordan ranking above other players, such as LeBron James, who is also frequently mentioned in the GOAT debate.\n"
     ]
    }
   ],
   "source": [
    "result = rag_chain_with_source.invoke(\"Who is the GOAT of NBA?\")\n",
    "relevance_score = result['answer']['relevance_score']\n",
    "final_answer = result['answer']['final_answer']\n",
    "\n",
    "print(f\"Relevance Score: {relevance_score}\")\n",
    "print(f\"Final Answer:\\n{final_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b426e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio Interface\n",
    "def process_question(question):\n",
    "    result = rag_chain_with_source.invoke(question)\n",
    "    relevance_score = result['answer']['relevance_score']\n",
    "    final_answer = result['answer']['final_answer']\n",
    "    return relevance_score, final_answer\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=process_question,\n",
    "    inputs=gr.Textbox(label=\"Enter your question\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Relevance Score\"),\n",
    "        gr.Textbox(label=\"Final Answer\")\n",
    "    ],\n",
    "    title=\"NBA Player Question Answering\",\n",
    "    description=\"Enter a question and get the relevance score, final answer, and sources from RAG.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e54d569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://1ab4ed007142e86579.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1ab4ed007142e86579.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(share=True, debug=False, auth=(\"admin\", \"pass1234\")) # with credentials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
