{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d17726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.docstore.document import Document\n",
    "from collections import Counter\n",
    "from langchain.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "592787d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16343\\AppData\\Local\\Temp\\ipykernel_16644\\2085501777.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(openai_api_key=\"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\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(openai_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b99b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_player_texts.csv\")  # Make sure this is your final file\n",
    "\n",
    "# Step 2: Initialize the character-based text splitter\n",
    "splitter = SemanticChunker(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453f3f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunking complete. Total chunks: 17139\n",
      "Example chunk:\n",
      "Alaa Abdelnaby (Arabic: علاء عبد النبي; born June 24, 1968) is an Egyptian-American former professional basketball player. He played college basketball for the Duke Blue Devils followed by a five-year National Basketball Association (NBA) career, and then stints in various other leagues. Abdelnaby is one of two Egyptian-born players in the history of the NBA, along with Abdel Nader. Abdelnaby works as a basketball broadcaster and analyst for NBCS Philadelphia, CBS Sports Network, and Westwood One Radio. Abdelnaby was born in Alexandria, Egypt, and moved to the United States with his family in 1971 at the age of two. His father was an engineer and his mother was a computer analyst who had moved to find better jobs.\n",
      "Metadata: {'player': 'Alaa Abdelnaby'}\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    player_name = row[\"player\"]\n",
    "    full_text = row[\"combined_text\"]\n",
    "\n",
    "    # Split the full text into overlapping chunks\n",
    "    text_chunks = splitter.split_text(full_text)\n",
    "\n",
    "    # Create LangChain Document objects with metadata\n",
    "    for chunk in text_chunks:\n",
    "        doc = Document(page_content=chunk, metadata={\"player\": player_name})\n",
    "        documents.append(doc)\n",
    "\n",
    "# Step 4: [Optional] Print some results\n",
    "print(f\"✅ Chunking complete. Total chunks: {len(documents)}\")\n",
    "print(\"Example chunk:\")\n",
    "print(documents[0].page_content)\n",
    "print(\"Metadata:\", documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26640758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LeBron James', 44), ('Kobe Bryant', 42), ('Michael Jackson', 38), (\"Shaquille O'Neal\", 38), ('Stephen Curry', 33)]\n"
     ]
    }
   ],
   "source": [
    "counter = Counter([doc.metadata[\"player\"] for doc in documents])\n",
    "print(counter.most_common(5))  # Show top 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88026ab",
   "metadata": {},
   "source": [
    "## Embedding and Vector Store Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "250f2579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [06:37<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "texts = [doc.page_content for doc in documents]\n",
    "metadatas = [doc.metadata for doc in documents]\n",
    "\n",
    "# Initialize storage\n",
    "all_embeddings = []\n",
    "all_texts = []\n",
    "all_metadata = []\n",
    "\n",
    "batch_size = 50  # Safe starting point\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    batch_meta = metadatas[i:i+batch_size]\n",
    "\n",
    "    try:\n",
    "        batch_embeddings = embedding.embed_documents(batch_texts)\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "        all_texts.extend(batch_texts)\n",
    "        all_metadata.extend(batch_meta)\n",
    "    except Exception as e:\n",
    "        print(f\"Batch {i} failed: {e}\")\n",
    "        time.sleep(60)  # Backoff for rate limiting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a09275",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding_pairs = list(zip(all_texts, all_embeddings))\n",
    "vectorstore = FAISS.from_embeddings(text_embedding_pairs, embedding=embedding, metadatas=all_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9adae842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector store created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "vectorstore.save_local(\"nba_vector_db_semantic\")\n",
    "print(\"✅ Vector store created and saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
